{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5. Transformers for token classification\n",
    "Max Base Points: 15\n",
    "- [x] Introduce fixes, mentioned in `TODO`s\n",
    "- [x] Your model also have to handle ukrainian and russian languages. Make sure to add `../data/mantis_analytics_location_detection/ru_geo_dataset.csv` (from https://www.kaggle.com/datasets/vladimirsydor/mantis-analytics-location-detection/data). Think about\n",
    "    - New Validation\n",
    "    - New Word Embeddings\n",
    "    - Maybe separate models\n",
    "    - IMPORTANT: Take into account `doc_id`\n",
    "    - Take into account that markup is far from ideal. Maybe pre-processing may help\n",
    "- [ ] Coming back to Lecture 3. F1 is the final production metric but it strongly depends on threshold. Maybe you can use some \"soft\" metric for model comparison ? \n",
    "- [x] Do we need additional post-processing ?\n",
    "- [x] Tune `BERT` / `DEBERTA` or other bert-like models on the whole dataset for more epochs, maybe re-write it. Tune all other hyper-params.\n",
    "- [ ] Try different optimizers lr schedulers \n",
    "- [ ] Implement Cross-Validation and add test houldout\n",
    "- [x] Make a submit to Kaggle\n",
    "- [ ] Additional points: first private score - 25 points, second private score - 15 points, third private score - 10 points\n",
    "- [ ] Do not hesitate to use `Discussion` and `Code` on Kaggle. All additional useful insights will be also granted with additional scores\n",
    "- [x] If you do not want to share with other competitors - you can share with lectors. It can be useful for Mantis usecase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General thoughts and approaches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined multibert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separated models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation nuances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some additional insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помітив, що в мене після файнтюнингу моделі, huggingface pipeline деякі токени, такі як декілька видів апострофів, дефіс і лапки, при об'єднанні в слова додає з пробілами. Через це якась кількість адрес/назв не поверталась в потрібному форматі. Наприклад `вул. Л. Лукʼяненка, 13`  видавалась в предікшені як `вул. Л. Лук ʼ яненка, 13`.  Підозрюю що в предікшені `nlp_ua_bert_baseline.csv` те саме було (в мене в якийсь момент був 1-в-1 скор з ним). Додав в постпроцесинг таку регулярку:\n",
    "```python\n",
    "if ent['score'] >= 0.95 and \"#\" not in ent['word']:\n",
    "    word = re.sub(r\"\\s*([ʼ\\''-])\\s*\", r\"\\1\", ent['word'])\n",
    "    res.append(word)\n",
    "```\n",
    "Це додало `+0.02` до LB скору"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ToDo**: think about more generalized approach -- match classified tokens with the original text and for the prediction return a substring of the original text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iasa_nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
